{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407d8947-5608-4af1-b569-af23c6f72a19",
   "metadata": {},
   "source": [
    "### Training your first model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b96a12-407e-4cf8-bdcf-b7bbf439d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download some test data:\n",
    "!ns-download-data nerfstudio --capture-name=poster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867622a-c0c3-41ee-aeca-c0cafc2a3028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "!ns-train nerfacto --data data/nerfstudio/poster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240ab700-09fa-40f3-bcb7-e0cad7dc7a33",
   "metadata": {},
   "source": [
    "Open next link to see viewr: http://galactica.lan:7007/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8945eb",
   "metadata": {},
   "source": [
    "For custom image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfdb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ns-process-data images --data imagess/ --output-dir processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [21:57:10] ğŸ‰ Done copying images with prefix 'frame_'.                                        \u001b]8;id=77901;file:///home/user/nerfstudio/nerfstudio/process_data/process_data_utils.py\u001b\\process_data_utils.py\u001b]8;;\u001b\\:\u001b]8;id=984440;file:///home/user/nerfstudio/nerfstudio/process_data/process_data_utils.py#340\u001b\\340\u001b]8;;\u001b\\\n",
    "# (   â—  ) Copying images...\n",
    "# ğŸŒ•  Running COLMAP feature extractor...tor...\n",
    "# [21:57:14] ğŸ‰ Done extracting COLMAP features.                                                       \u001b]8;id=269736;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py\u001b\\colmap_utils.py\u001b]8;;\u001b\\:\u001b]8;id=853412;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py#137\u001b\\137\u001b]8;;\u001b\\\n",
    "# Downloading vocab tree... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸ 100% 0:00:0100:01\n",
    "# ğŸƒ  Running COLMAP feature matcher...r...\n",
    "# [21:57:20] ğŸ‰ Done matching COLMAP features.                                                         \u001b]8;id=81371;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py\u001b\\colmap_utils.py\u001b]8;;\u001b\\:\u001b]8;id=36854;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py#151\u001b\\151\u001b]8;;\u001b\\\n",
    "# â—¡ Running COLMAP bundle adjustment... (This may take a while)0m\n",
    "# [21:57:33] ğŸ‰ Done COLMAP bundle adjustment.                                                         \u001b]8;id=358071;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py\u001b\\colmap_utils.py\u001b]8;;\u001b\\:\u001b]8;id=490616;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py#173\u001b\\173\u001b]8;;\u001b\\\n",
    "# b Refine intrinsics...0m\n",
    "# [21:57:34] ğŸ‰ Done refining intrinsics.                                                              \u001b]8;id=867641;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py\u001b\\colmap_utils.py\u001b]8;;\u001b\\:\u001b]8;id=479607;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py#184\u001b\\184\u001b]8;;\u001b\\\n",
    "#   Saving results to transforms.json\n",
    "#            ğŸ‰ ğŸ‰ ğŸ‰ All DONE ğŸ‰ ğŸ‰ ğŸ‰                                                \u001b]8;id=840132;file:///home/user/nerfstudio/nerfstudio/process_data/images_to_nerfstudio_dataset.py\u001b\\images_to_nerfstudio_dataset.py\u001b]8;;\u001b\\:\u001b]8;id=860325;file:///home/user/nerfstudio/nerfstudio/process_data/images_to_nerfstudio_dataset.py#132\u001b\\132\u001b]8;;\u001b\\\n",
    "#            Starting with 65 images                                                   \u001b]8;id=30284;file:///home/user/nerfstudio/nerfstudio/process_data/images_to_nerfstudio_dataset.py\u001b\\images_to_nerfstudio_dataset.py\u001b]8;;\u001b\\:\u001b]8;id=960686;file:///home/user/nerfstudio/nerfstudio/process_data/images_to_nerfstudio_dataset.py#135\u001b\\135\u001b]8;;\u001b\\\n",
    "#            Colmap matched 44 images                                                  \u001b]8;id=428191;file:///home/user/nerfstudio/nerfstudio/process_data/images_to_nerfstudio_dataset.py\u001b\\images_to_nerfstudio_dataset.py\u001b]8;;\u001b\\:\u001b]8;id=125296;file:///home/user/nerfstudio/nerfstudio/process_data/images_to_nerfstudio_dataset.py#135\u001b\\135\u001b]8;;\u001b\\\n",
    "#            COLMAP only found poses for 67.69% of the images.                         \u001b]8;id=470291;file:///home/user/nerfstudio/nerfstudio/process_data/images_to_nerfstudio_dataset.py\u001b\\images_to_nerfstudio_dataset.py\u001b]8;;\u001b\\:\u001b]8;id=322577;file:///home/user/nerfstudio/nerfstudio/process_data/images_to_nerfstudio_dataset.py#135\u001b\\135\u001b]8;;\u001b\\\n",
    "#            This isn't great, but may be ok.                                                                             \n",
    "#            Missing poses can be caused by a variety of reasons, such poor scene                                         \n",
    "#            coverage, blurry images, or large exposure changes.             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be112bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ns-train nerfacto --logging.local-writer.enable=False --data processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8718057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [21:58:19] Using --data alias for --data.pipeline.datamanager.data                                          \u001b]8;id=777577;file:///home/user/nerfstudio/nerfstudio/scripts/train.py\u001b\\train.py\u001b]8;;\u001b\\:\u001b]8;id=544363;file:///home/user/nerfstudio/nerfstudio/scripts/train.py#230\u001b\\230\u001b]8;;\u001b\\\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TrainerConfig(\n",
    "#     _target=<class 'nerfstudio.engine.trainer.Trainer'>,\n",
    "#     output_dir=PosixPath('outputs'),\n",
    "#     method_name='nerfacto',\n",
    "#     experiment_name=None,\n",
    "#     project_name='nerfstudio-project',\n",
    "#     timestamp='2024-07-08_215819',\n",
    "#     machine=MachineConfig(seed=42, num_devices=1, num_machines=1, machine_rank=0, dist_url='auto', device_type='cuda'),\n",
    "#     logging=LoggingConfig(\n",
    "#         relative_log_dir=PosixPath('.'),\n",
    "#         steps_per_log=10,\n",
    "#         max_buffer_size=20,\n",
    "#         local_writer=LocalWriterConfig(\n",
    "#             _target=<class 'nerfstudio.utils.writer.LocalWriter'>,\n",
    "#             enable=False,\n",
    "#             stats_to_track=(\n",
    "#                 <EventName.ITER_TRAIN_TIME: 'Train Iter (time)'>,\n",
    "#                 <EventName.TRAIN_RAYS_PER_SEC: 'Train Rays / Sec'>,\n",
    "#                 <EventName.CURR_TEST_PSNR: 'Test PSNR'>,\n",
    "#                 <EventName.VIS_RAYS_PER_SEC: 'Vis Rays / Sec'>,\n",
    "#                 <EventName.TEST_RAYS_PER_SEC: 'Test Rays / Sec'>,\n",
    "#                 <EventName.ETA: 'ETA (time)'>\n",
    "#             ),\n",
    "#             max_log_size=10\n",
    "#         ),\n",
    "#         profiler='basic'\n",
    "#     ),\n",
    "#     viewer=ViewerConfig(\n",
    "#         relative_log_filename='viewer_log_filename.txt',\n",
    "#         websocket_port=None,\n",
    "#         websocket_port_default=7007,\n",
    "#         websocket_host='0.0.0.0',\n",
    "#         num_rays_per_chunk=32768,\n",
    "#         max_num_display_images=512,\n",
    "#         quit_on_train_completion=False,\n",
    "#         image_format='jpeg',\n",
    "#         jpeg_quality=75,\n",
    "#         make_share_url=False,\n",
    "#         camera_frustum_scale=0.1,\n",
    "#         default_composite_depth=True\n",
    "#     ),\n",
    "#     pipeline=VanillaPipelineConfig(\n",
    "#         _target=<class 'nerfstudio.pipelines.base_pipeline.VanillaPipeline'>,\n",
    "#         datamanager=ParallelDataManagerConfig(\n",
    "#             _target=<class 'nerfstudio.data.datamanagers.parallel_datamanager.ParallelDataManager'>,\n",
    "#             data=PosixPath('processed'),\n",
    "#             masks_on_gpu=False,\n",
    "#             images_on_gpu=False,\n",
    "#             dataparser=NerfstudioDataParserConfig(\n",
    "#                 _target=<class 'nerfstudio.data.dataparsers.nerfstudio_dataparser.Nerfstudio'>,\n",
    "#                 data=PosixPath('.'),\n",
    "#                 scale_factor=1.0,\n",
    "#                 downscale_factor=None,\n",
    "#                 scene_scale=1.0,\n",
    "#                 orientation_method='up',\n",
    "#                 center_method='poses',\n",
    "#                 auto_scale_poses=True,\n",
    "#                 eval_mode='fraction',\n",
    "#                 train_split_fraction=0.9,\n",
    "#                 eval_interval=8,\n",
    "#                 depth_unit_scale_factor=0.001,\n",
    "#                 mask_color=None,\n",
    "#                 load_3D_points=False\n",
    "#             ),\n",
    "#             train_num_rays_per_batch=4096,\n",
    "#             train_num_images_to_sample_from=-1,\n",
    "#             train_num_times_to_repeat_images=-1,\n",
    "#             eval_num_rays_per_batch=4096,\n",
    "#             eval_num_images_to_sample_from=-1,\n",
    "#             eval_num_times_to_repeat_images=-1,\n",
    "#             eval_image_indices=(0,),\n",
    "#             collate_fn=<function nerfstudio_collate at 0x7f189d1adab0>,\n",
    "#             camera_res_scale_factor=1.0,\n",
    "#             patch_size=1,\n",
    "#             camera_optimizer=None,\n",
    "#             pixel_sampler=PixelSamplerConfig(\n",
    "#                 _target=<class 'nerfstudio.data.pixel_samplers.PixelSampler'>,\n",
    "#                 num_rays_per_batch=4096,\n",
    "#                 keep_full_image=False,\n",
    "#                 is_equirectangular=False,\n",
    "#                 ignore_mask=False,\n",
    "#                 fisheye_crop_radius=None,\n",
    "#                 rejection_sample_mask=True,\n",
    "#                 max_num_iterations=100\n",
    "#             ),\n",
    "#             num_processes=1,\n",
    "#             queue_size=2,\n",
    "#             max_thread_workers=None\n",
    "#         ),\n",
    "#         model=NerfactoModelConfig(\n",
    "#             _target=<class 'nerfstudio.models.nerfacto.NerfactoModel'>,\n",
    "#             enable_collider=True,\n",
    "#             collider_params={'near_plane': 2.0, 'far_plane': 6.0},\n",
    "#             loss_coefficients={'rgb_loss_coarse': 1.0, 'rgb_loss_fine': 1.0},\n",
    "#             eval_num_rays_per_chunk=32768,\n",
    "#             prompt=None,\n",
    "#             near_plane=0.05,\n",
    "#             far_plane=1000.0,\n",
    "#             background_color='last_sample',\n",
    "#             hidden_dim=64,\n",
    "#             hidden_dim_color=64,\n",
    "#             hidden_dim_transient=64,\n",
    "#             num_levels=16,\n",
    "#             base_res=16,\n",
    "#             max_res=2048,\n",
    "#             log2_hashmap_size=19,\n",
    "#             features_per_level=2,\n",
    "#             num_proposal_samples_per_ray=(256, 96),\n",
    "#             num_nerf_samples_per_ray=48,\n",
    "#             proposal_update_every=5,\n",
    "#             proposal_warmup=5000,\n",
    "#             num_proposal_iterations=2,\n",
    "#             use_same_proposal_network=False,\n",
    "#             proposal_net_args_list=[\n",
    "#                 {'hidden_dim': 16, 'log2_hashmap_size': 17, 'num_levels': 5, 'max_res': 128, 'use_linear': False},\n",
    "#                 {'hidden_dim': 16, 'log2_hashmap_size': 17, 'num_levels': 5, 'max_res': 256, 'use_linear': False}\n",
    "#             ],\n",
    "#             proposal_initial_sampler='piecewise',\n",
    "#             interlevel_loss_mult=1.0,\n",
    "#             distortion_loss_mult=0.002,\n",
    "#             orientation_loss_mult=0.0001,\n",
    "#             pred_normal_loss_mult=0.001,\n",
    "#             use_proposal_weight_anneal=True,\n",
    "#             use_appearance_embedding=True,\n",
    "#             use_average_appearance_embedding=True,\n",
    "#             proposal_weights_anneal_slope=10.0,\n",
    "#             proposal_weights_anneal_max_num_iters=1000,\n",
    "#             use_single_jitter=True,\n",
    "#             predict_normals=False,\n",
    "#             disable_scene_contraction=False,\n",
    "#             use_gradient_scaling=False,\n",
    "#             implementation='tcnn',\n",
    "#             appearance_embed_dim=32,\n",
    "#             average_init_density=0.01,\n",
    "#             camera_optimizer=CameraOptimizerConfig(\n",
    "#                 _target=<class 'nerfstudio.cameras.camera_optimizers.CameraOptimizer'>,\n",
    "#                 mode='SO3xR3',\n",
    "#                 trans_l2_penalty=0.01,\n",
    "#                 rot_l2_penalty=0.001,\n",
    "#                 optimizer=None,\n",
    "#                 scheduler=None\n",
    "#             )\n",
    "#         )\n",
    "#     ),\n",
    "#     optimizers={\n",
    "#         'proposal_networks': {\n",
    "#             'optimizer': AdamOptimizerConfig(\n",
    "#                 _target=<class 'torch.optim.adam.Adam'>,\n",
    "#                 lr=0.01,\n",
    "#                 eps=1e-15,\n",
    "#                 max_norm=None,\n",
    "#                 weight_decay=0\n",
    "#             ),\n",
    "#             'scheduler': ExponentialDecaySchedulerConfig(\n",
    "#                 _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,\n",
    "#                 lr_pre_warmup=1e-08,\n",
    "#                 lr_final=0.0001,\n",
    "#                 warmup_steps=0,\n",
    "#                 max_steps=200000,\n",
    "#                 ramp='cosine'\n",
    "#             )\n",
    "#         },\n",
    "#         'fields': {\n",
    "#             'optimizer': AdamOptimizerConfig(\n",
    "#                 _target=<class 'torch.optim.adam.Adam'>,\n",
    "#                 lr=0.01,\n",
    "#                 eps=1e-15,\n",
    "#                 max_norm=None,\n",
    "#                 weight_decay=0\n",
    "#             ),\n",
    "#             'scheduler': ExponentialDecaySchedulerConfig(\n",
    "#                 _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,\n",
    "#                 lr_pre_warmup=1e-08,\n",
    "#                 lr_final=0.0001,\n",
    "#                 warmup_steps=0,\n",
    "#                 max_steps=200000,\n",
    "#                 ramp='cosine'\n",
    "#             )\n",
    "#         },\n",
    "#         'camera_opt': {\n",
    "#             'optimizer': AdamOptimizerConfig(\n",
    "#                 _target=<class 'torch.optim.adam.Adam'>,\n",
    "#                 lr=0.001,\n",
    "#                 eps=1e-15,\n",
    "#                 max_norm=None,\n",
    "#                 weight_decay=0\n",
    "#             ),\n",
    "#             'scheduler': ExponentialDecaySchedulerConfig(\n",
    "#                 _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,\n",
    "#                 lr_pre_warmup=1e-08,\n",
    "#                 lr_final=0.0001,\n",
    "#                 warmup_steps=0,\n",
    "#                 max_steps=5000,\n",
    "#                 ramp='cosine'\n",
    "#             )\n",
    "#         }\n",
    "#     },\n",
    "#     vis='viewer',\n",
    "#     data=PosixPath('processed'),\n",
    "#     prompt=None,\n",
    "#     relative_model_dir=PosixPath('nerfstudio_models'),\n",
    "#     load_scheduler=True,\n",
    "#     steps_per_save=2000,\n",
    "#     steps_per_eval_batch=500,\n",
    "#     steps_per_eval_image=500,\n",
    "#     steps_per_eval_all_images=25000,\n",
    "#     max_num_iterations=30000,\n",
    "#     mixed_precision=True,\n",
    "#     use_grad_scaler=False,\n",
    "#     save_only_latest_checkpoint=True,\n",
    "#     load_dir=None,\n",
    "#     load_step=None,\n",
    "#     load_config=None,\n",
    "#     load_checkpoint=None,\n",
    "#     log_gradients=False,\n",
    "#     gradient_accumulation_steps={}\n",
    "# )\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#            Saving config to: outputs/processed/nerfacto/2024-07-08_215819/config.yml            \u001b]8;id=447289;file:///home/user/nerfstudio/nerfstudio/configs/experiment_config.py\u001b\\experiment_config.py\u001b]8;;\u001b\\:\u001b]8;id=714557;file:///home/user/nerfstudio/nerfstudio/configs/experiment_config.py#136\u001b\\136\u001b]8;;\u001b\\\n",
    "#            Saving checkpoints to: outputs/processed/nerfacto/2024-07-08_215819/nerfstudio_models          \u001b]8;id=234053;file:///home/user/nerfstudio/nerfstudio/engine/trainer.py\u001b\\trainer.py\u001b]8;;\u001b\\:\u001b]8;id=146316;file:///home/user/nerfstudio/nerfstudio/engine/trainer.py#137\u001b\\137\u001b]8;;\u001b\\\n",
    "#            Auto image downscale factor of 4                                                 \u001b]8;id=91161;file:///home/user/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\nerfstudio_dataparser.py\u001b]8;;\u001b\\:\u001b]8;id=619176;file:///home/user/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#484\u001b\\484\u001b]8;;\u001b\\\n",
    "# Started threads\n",
    "# Setting up evaluation dataset...\n",
    "# Caching all 4 images.\n",
    "# Loading data batch â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:00\n",
    "# Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /home/user/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
    "# 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 233M/233M [00:02<00:00, 100MB/s]\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ viser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "# â”‚             â•·                       â”‚\n",
    "# â”‚   HTTP      â”‚ http://0.0.0.0:7007   â”‚\n",
    "# â”‚   Websocket â”‚ ws://0.0.0.0:7007     â”‚\n",
    "# â”‚             â•µ                       â”‚\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "# [NOTE] Not running eval iterations since only viewer is enabled.\n",
    "# Use --vis {wandb, tensorboard, viewer+wandb, viewer+tensorboard} to run with eval.\n",
    "# No Nerfstudio checkpoint to load, so training from scratch.\n",
    "# Disabled comet/tensorboard/wandb event writers\n",
    "# [21:58:28] disabled local writer                                                                           \u001b]8;id=208496;file:///home/user/nerfstudio/nerfstudio/utils/writer.py\u001b\\writer.py\u001b]8;;\u001b\\:\u001b]8;id=750800;file:///home/user/nerfstudio/nerfstudio/utils/writer.py#185\u001b\\185\u001b]8;;\u001b\\\n",
    "# (viser) Connection opened (0, 1 total), 295 persistent messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aa5881",
   "metadata": {},
   "source": [
    "For custom video data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f9f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ns-process-data video --data videoo/video_2024-07-02_18-43-16.mp4 --output-dir processed_video_1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2acdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of frames in video: 2157\n",
    "# Number of frames to extract: 309\n",
    "# [21:55:00] ğŸ‰ Done converting video to images.                                                 \u001b]8;id=646594;file:///home/user/nerfstudio/nerfstudio/process_data/process_data_utils.py\u001b\\process_data_utils.py\u001b]8;;\u001b\\:\u001b]8;id=576143;file:///home/user/nerfstudio/nerfstudio/process_data/process_data_utils.py#219\u001b\\219\u001b]8;;\u001b\\\n",
    "# (    â— ) Converting video to images...\n",
    "# ğŸŒ—  Running COLMAP feature extractor...tor...\n",
    "# [21:55:04] ğŸ‰ Done extracting COLMAP features.                                                       \u001b]8;id=264983;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py\u001b\\colmap_utils.py\u001b]8;;\u001b\\:\u001b]8;id=831919;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py#137\u001b\\137\u001b]8;;\u001b\\\n",
    "# ğŸš¶  Running COLMAP feature matcher...0m\n",
    "# [21:55:17] ğŸ‰ Done matching COLMAP features.                                                         \u001b]8;id=106956;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py\u001b\\colmap_utils.py\u001b]8;;\u001b\\:\u001b]8;id=289375;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py#151\u001b\\151\u001b]8;;\u001b\\\n",
    "# âŠ™ Running COLMAP bundle adjustment... (This may take a while)0m\n",
    "# [21:55:59] ğŸ‰ Done COLMAP bundle adjustment.                                                         \u001b]8;id=898019;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py\u001b\\colmap_utils.py\u001b]8;;\u001b\\:\u001b]8;id=148746;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py#173\u001b\\173\u001b]8;;\u001b\\\n",
    "# b Refine intrinsics...0m\n",
    "# [21:56:02] ğŸ‰ Done refining intrinsics.                                                              \u001b]8;id=629284;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py\u001b\\colmap_utils.py\u001b]8;;\u001b\\:\u001b]8;id=732496;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py#184\u001b\\184\u001b]8;;\u001b\\\n",
    "# . Saving results to transforms.json0m\n",
    "# [21:56:03] ğŸ‰ ğŸ‰ ğŸ‰ All DONE ğŸ‰ ğŸ‰ ğŸ‰                                                 \u001b]8;id=344626;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py\u001b\\video_to_nerfstudio_dataset.py\u001b]8;;\u001b\\:\u001b]8;id=162172;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py#142\u001b\\142\u001b]8;;\u001b\\\n",
    "#            Starting with 2157 video frames                                            \u001b]8;id=941317;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py\u001b\\video_to_nerfstudio_dataset.py\u001b]8;;\u001b\\:\u001b]8;id=644603;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py#145\u001b\\145\u001b]8;;\u001b\\\n",
    "#            We extracted 309 images with prefix 'frame_'                               \u001b]8;id=869437;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py\u001b\\video_to_nerfstudio_dataset.py\u001b]8;;\u001b\\:\u001b]8;id=930408;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py#145\u001b\\145\u001b]8;;\u001b\\\n",
    "#            Colmap matched 308 images                                                  \u001b]8;id=757911;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py\u001b\\video_to_nerfstudio_dataset.py\u001b]8;;\u001b\\:\u001b]8;id=893839;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py#145\u001b\\145\u001b]8;;\u001b\\\n",
    "#            COLMAP found poses for 99.68% of the images.                               \u001b]8;id=3769;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py\u001b\\video_to_nerfstudio_dataset.py\u001b]8;;\u001b\\:\u001b]8;id=533736;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py#145\u001b\\145\u001b]8;;\u001b\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c2747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ns-train nerfacto-big --logging.local-writer.enable=False --data processed_video_1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374109ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TrainerConfig(\n",
    "#     _target=<class 'nerfstudio.engine.trainer.Trainer'>,\n",
    "#     output_dir=PosixPath('outputs'),\n",
    "#     method_name='nerfacto',\n",
    "#     experiment_name=None,\n",
    "#     project_name='nerfstudio-project',\n",
    "#     timestamp='2024-07-02_200125',\n",
    "#     machine=MachineConfig(seed=42, num_devices=1, num_machines=1, machine_rank=0, dist_url='auto', device_type='cuda'),\n",
    "#     logging=LoggingConfig(\n",
    "#         relative_log_dir=PosixPath('.'),\n",
    "#         steps_per_log=10,\n",
    "#         max_buffer_size=20,\n",
    "#         local_writer=LocalWriterConfig(\n",
    "#             _target=<class 'nerfstudio.utils.writer.LocalWriter'>,\n",
    "#             enable=False,\n",
    "#             stats_to_track=(\n",
    "#                 <EventName.ITER_TRAIN_TIME: 'Train Iter (time)'>,\n",
    "#                 <EventName.TRAIN_RAYS_PER_SEC: 'Train Rays / Sec'>,\n",
    "#                 <EventName.CURR_TEST_PSNR: 'Test PSNR'>,\n",
    "#                 <EventName.VIS_RAYS_PER_SEC: 'Vis Rays / Sec'>,\n",
    "#                 <EventName.TEST_RAYS_PER_SEC: 'Test Rays / Sec'>,\n",
    "#                 <EventName.ETA: 'ETA (time)'>\n",
    "#             ),\n",
    "#             max_log_size=10\n",
    "#         ),\n",
    "#         profiler='basic'\n",
    "#     ),\n",
    "#     viewer=ViewerConfig(\n",
    "#         relative_log_filename='viewer_log_filename.txt',\n",
    "#         websocket_port=None,\n",
    "#         websocket_port_default=7007,\n",
    "#         websocket_host='0.0.0.0',\n",
    "#         num_rays_per_chunk=32768,\n",
    "#         max_num_display_images=512,\n",
    "#         quit_on_train_completion=False,\n",
    "#         image_format='jpeg',\n",
    "#         jpeg_quality=75,\n",
    "#         make_share_url=False,\n",
    "#         camera_frustum_scale=0.1,\n",
    "#         default_composite_depth=True\n",
    "#     ),\n",
    "#     pipeline=VanillaPipelineConfig(\n",
    "#         _target=<class 'nerfstudio.pipelines.base_pipeline.VanillaPipeline'>,\n",
    "#         datamanager=ParallelDataManagerConfig(\n",
    "#             _target=<class 'nerfstudio.data.datamanagers.parallel_datamanager.ParallelDataManager'>,\n",
    "#             data=PosixPath('processed_video_1'),\n",
    "#             masks_on_gpu=False,\n",
    "#             images_on_gpu=False,\n",
    "#             dataparser=NerfstudioDataParserConfig(\n",
    "#                 _target=<class 'nerfstudio.data.dataparsers.nerfstudio_dataparser.Nerfstudio'>,\n",
    "#                 data=PosixPath('.'),\n",
    "#                 scale_factor=1.0,\n",
    "#                 downscale_factor=None,\n",
    "#                 scene_scale=1.0,\n",
    "#                 orientation_method='up',\n",
    "#                 center_method='poses',\n",
    "#                 auto_scale_poses=True,\n",
    "#                 eval_mode='fraction',\n",
    "#                 train_split_fraction=0.9,\n",
    "#                 eval_interval=8,\n",
    "#                 depth_unit_scale_factor=0.001,\n",
    "#                 mask_color=None,\n",
    "#                 load_3D_points=False\n",
    "#             ),\n",
    "#             train_num_rays_per_batch=8192,\n",
    "#             train_num_images_to_sample_from=-1,\n",
    "#             train_num_times_to_repeat_images=-1,\n",
    "#             eval_num_rays_per_batch=4096,\n",
    "#             eval_num_images_to_sample_from=-1,\n",
    "#             eval_num_times_to_repeat_images=-1,\n",
    "#             eval_image_indices=(0,),\n",
    "#             collate_fn=<function nerfstudio_collate at 0x7f4ab33b9ab0>,\n",
    "#             camera_res_scale_factor=1.0,\n",
    "#             patch_size=1,\n",
    "#             camera_optimizer=None,\n",
    "#             pixel_sampler=PixelSamplerConfig(\n",
    "#                 _target=<class 'nerfstudio.data.pixel_samplers.PixelSampler'>,\n",
    "#                 num_rays_per_batch=4096,\n",
    "#                 keep_full_image=False,\n",
    "#                 is_equirectangular=False,\n",
    "#                 ignore_mask=False,\n",
    "#                 fisheye_crop_radius=None,\n",
    "#                 rejection_sample_mask=True,\n",
    "#                 max_num_iterations=100\n",
    "#             ),\n",
    "#             num_processes=1,\n",
    "#             queue_size=2,\n",
    "#             max_thread_workers=None\n",
    "#         ),\n",
    "#         model=NerfactoModelConfig(\n",
    "#             _target=<class 'nerfstudio.models.nerfacto.NerfactoModel'>,\n",
    "#             enable_collider=True,\n",
    "#             collider_params={'near_plane': 2.0, 'far_plane': 6.0},\n",
    "#             loss_coefficients={'rgb_loss_coarse': 1.0, 'rgb_loss_fine': 1.0},\n",
    "#             eval_num_rays_per_chunk=32768,\n",
    "#             prompt=None,\n",
    "#             near_plane=0.05,\n",
    "#             far_plane=1000.0,\n",
    "#             background_color='last_sample',\n",
    "#             hidden_dim=128,\n",
    "#             hidden_dim_color=128,\n",
    "#             hidden_dim_transient=64,\n",
    "#             num_levels=16,\n",
    "#             base_res=16,\n",
    "#             max_res=4096,\n",
    "#             log2_hashmap_size=21,\n",
    "#             features_per_level=2,\n",
    "#             num_proposal_samples_per_ray=(512, 256),\n",
    "#             num_nerf_samples_per_ray=128,\n",
    "#             proposal_update_every=5,\n",
    "#             proposal_warmup=5000,\n",
    "#             num_proposal_iterations=2,\n",
    "#             use_same_proposal_network=False,\n",
    "#             proposal_net_args_list=[\n",
    "#                 {'hidden_dim': 16, 'log2_hashmap_size': 17, 'num_levels': 5, 'max_res': 128, 'use_linear': False},\n",
    "#                 {'hidden_dim': 16, 'log2_hashmap_size': 17, 'num_levels': 5, 'max_res': 256, 'use_linear': False}\n",
    "#             ],\n",
    "#             proposal_initial_sampler='piecewise',\n",
    "#             interlevel_loss_mult=1.0,\n",
    "#             distortion_loss_mult=0.002,\n",
    "#             orientation_loss_mult=0.0001,\n",
    "#             pred_normal_loss_mult=0.001,\n",
    "#             use_proposal_weight_anneal=True,\n",
    "#             use_appearance_embedding=True,\n",
    "#             use_average_appearance_embedding=True,\n",
    "#             proposal_weights_anneal_slope=10.0,\n",
    "#             proposal_weights_anneal_max_num_iters=5000,\n",
    "#             use_single_jitter=True,\n",
    "#             predict_normals=False,\n",
    "#             disable_scene_contraction=False,\n",
    "#             use_gradient_scaling=False,\n",
    "#             implementation='tcnn',\n",
    "#             appearance_embed_dim=128,\n",
    "#             average_init_density=0.01,\n",
    "#             camera_optimizer=CameraOptimizerConfig(\n",
    "#                 _target=<class 'nerfstudio.cameras.camera_optimizers.CameraOptimizer'>,\n",
    "#                 mode='SO3xR3',\n",
    "#                 trans_l2_penalty=0.01,\n",
    "#                 rot_l2_penalty=0.001,\n",
    "#                 optimizer=None,\n",
    "#                 scheduler=None\n",
    "#             )\n",
    "#         )\n",
    "#     ),\n",
    "#     optimizers={\n",
    "#         'proposal_networks': {\n",
    "#             'optimizer': RAdamOptimizerConfig(\n",
    "#                 _target=<class 'torch.optim.radam.RAdam'>,\n",
    "#                 lr=0.01,\n",
    "#                 eps=1e-15,\n",
    "#                 max_norm=None,\n",
    "#                 weight_decay=0\n",
    "#             ),\n",
    "#             'scheduler': None\n",
    "#         },\n",
    "#         'fields': {\n",
    "#             'optimizer': RAdamOptimizerConfig(\n",
    "#                 _target=<class 'torch.optim.radam.RAdam'>,\n",
    "#                 lr=0.01,\n",
    "#                 eps=1e-15,\n",
    "#                 max_norm=None,\n",
    "#                 weight_decay=0\n",
    "#             ),\n",
    "#             'scheduler': ExponentialDecaySchedulerConfig(\n",
    "#                 _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,\n",
    "#                 lr_pre_warmup=1e-08,\n",
    "#                 lr_final=0.0001,\n",
    "#                 warmup_steps=0,\n",
    "#                 max_steps=50000,\n",
    "#                 ramp='cosine'\n",
    "#             )\n",
    "#         },\n",
    "#         'camera_opt': {\n",
    "#             'optimizer': AdamOptimizerConfig(\n",
    "#                 _target=<class 'torch.optim.adam.Adam'>,\n",
    "#                 lr=0.001,\n",
    "#                 eps=1e-15,\n",
    "#                 max_norm=None,\n",
    "#                 weight_decay=0\n",
    "#             ),\n",
    "#             'scheduler': ExponentialDecaySchedulerConfig(\n",
    "#                 _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,\n",
    "#                 lr_pre_warmup=1e-08,\n",
    "#                 lr_final=0.0001,\n",
    "#                 warmup_steps=0,\n",
    "#                 max_steps=5000,\n",
    "#                 ramp='cosine'\n",
    "#             )\n",
    "#         }\n",
    "#     },\n",
    "#     vis='viewer',\n",
    "#     data=PosixPath('processed_video_1'),\n",
    "#     prompt=None,\n",
    "#     relative_model_dir=PosixPath('nerfstudio_models'),\n",
    "#     load_scheduler=True,\n",
    "#     steps_per_save=2000,\n",
    "#     steps_per_eval_batch=500,\n",
    "#     steps_per_eval_image=500,\n",
    "#     steps_per_eval_all_images=25000,\n",
    "#     max_num_iterations=100000,\n",
    "#     mixed_precision=True,\n",
    "#     use_grad_scaler=False,\n",
    "#     save_only_latest_checkpoint=True,\n",
    "#     load_dir=None,\n",
    "#     load_step=None,\n",
    "#     load_config=None,\n",
    "#     load_checkpoint=None,\n",
    "#     log_gradients=False,\n",
    "#     gradient_accumulation_steps={}\n",
    "# )\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#            Saving config to: outputs/processed_video_1/nerfacto/2024-07-02_200125/config.yml    \u001b]8;id=484655;file:///home/user/nerfstudio/nerfstudio/configs/experiment_config.py\u001b\\experiment_config.py\u001b]8;;\u001b\\:\u001b]8;id=152522;file:///home/user/nerfstudio/nerfstudio/configs/experiment_config.py#136\u001b\\136\u001b]8;;\u001b\\\n",
    "#            Saving checkpoints to: outputs/processed_video_1/nerfacto/2024-07-02_200125/nerfstudio_models  \u001b]8;id=234053;file:///home/user/nerfstudio/nerfstudio/engine/trainer.py\u001b\\trainer.py\u001b]8;;\u001b\\:\u001b]8;id=146316;file:///home/user/nerfstudio/nerfstudio/engine/trainer.py#137\u001b\\137\u001b]8;;\u001b\\\n",
    "#            Auto image downscale factor of 1                                                 \u001b]8;id=91161;file:///home/user/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\nerfstudio_dataparser.py\u001b]8;;\u001b\\:\u001b]8;id=619176;file:///home/user/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#484\u001b\\484\u001b]8;;\u001b\\\n",
    "# Started threads\n",
    "# Setting up evaluation dataset...\n",
    "# Caching all 30 images.\n",
    "# Loading data batch â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  44% 0:00:01â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ viser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "# â”‚             â•·                       â”‚\n",
    "# â”‚   HTTP      â”‚ http://0.0.0.0:7007   â”‚\n",
    "# â”‚   Websocket â”‚ ws://0.0.0.0:7007     â”‚\n",
    "# â”‚             â•µ                       â”‚\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "# Loading data batch â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:00m 0:00:01\n",
    "# [NOTE] Not running eval iterations since only viewer is enabled.\n",
    "# Use --vis {wandb, tensorboard, viewer+wandb, viewer+tensorboard} to run with eval.\n",
    "# No Nerfstudio checkpoint to load, so training from scratch.\n",
    "# Disabled comet/tensorboard/wandb event writers\n",
    "# [20:01:32] disabled local writer                                                                           \u001b]8;id=45561;file:///home/user/nerfstudio/nerfstudio/utils/writer.py\u001b\\writer.py\u001b]8;;\u001b\\:\u001b]8;id=765179;file:///home/user/nerfstudio/nerfstudio/utils/writer.py#185\u001b\\185\u001b]8;;\u001b\\\n",
    "# (viser) Connection opened (0, 1 total), 1485 persistent messages\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ‰ Training Finished ğŸ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "# â”‚                        â•·                                                                          â”‚\n",
    "# â”‚   Config File          â”‚ outputs/processed_video_1/nerfacto/2024-07-02_200125/config.yml          â”‚\n",
    "# â”‚   Checkpoint Directory â”‚ outputs/processed_video_1/nerfacto/2024-07-02_200125/nerfstudio_models   â”‚\n",
    "# â”‚                        â•µ                                                                          â”‚\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "#                                                    Use ctrl+c to quit                                                   \n",
    "# (viser) Connection closed (0, 0 total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8253ec70",
   "metadata": {},
   "source": [
    "# KIRI Engine Capture.\n",
    "\n",
    "Nerfstudio can trained from data processed by the KIRI Engine app. \n",
    "This works for both Android and iPhone and does not require a LiDAR supported device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70619e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ns-train nerfacto --logging.local-writer.enable=False --data kiri_engine/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [12:12:38] Using --data alias for --data.pipeline.datamanager.data                                          \u001b]8;id=731739;file:///home/user/nerfstudio/nerfstudio/scripts/train.py\u001b\\train.py\u001b]8;;\u001b\\:\u001b]8;id=672950;file:///home/user/nerfstudio/nerfstudio/scripts/train.py#230\u001b\\230\u001b]8;;\u001b\\\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TrainerConfig(\n",
    "#     _target=<class 'nerfstudio.engine.trainer.Trainer'>,\n",
    "#     output_dir=PosixPath('outputs'),\n",
    "#     method_name='nerfacto',\n",
    "#     experiment_name=None,\n",
    "#     project_name='nerfstudio-project',\n",
    "#     timestamp='2024-07-09_121238',\n",
    "#     machine=MachineConfig(seed=42, num_devices=1, num_machines=1, machine_rank=0, dist_url='auto', device_type='cuda'),\n",
    "#     logging=LoggingConfig(\n",
    "#         relative_log_dir=PosixPath('.'),\n",
    "#         steps_per_log=10,\n",
    "#         max_buffer_size=20,\n",
    "#         local_writer=LocalWriterConfig(\n",
    "#             _target=<class 'nerfstudio.utils.writer.LocalWriter'>,\n",
    "#             enable=False,\n",
    "#             stats_to_track=(\n",
    "#                 <EventName.ITER_TRAIN_TIME: 'Train Iter (time)'>,\n",
    "#                 <EventName.TRAIN_RAYS_PER_SEC: 'Train Rays / Sec'>,\n",
    "#                 <EventName.CURR_TEST_PSNR: 'Test PSNR'>,\n",
    "#                 <EventName.VIS_RAYS_PER_SEC: 'Vis Rays / Sec'>,\n",
    "#                 <EventName.TEST_RAYS_PER_SEC: 'Test Rays / Sec'>,\n",
    "#                 <EventName.ETA: 'ETA (time)'>\n",
    "#             ),\n",
    "#             max_log_size=10\n",
    "#         ),\n",
    "#         profiler='basic'\n",
    "#     ),\n",
    "#     viewer=ViewerConfig(\n",
    "#         relative_log_filename='viewer_log_filename.txt',\n",
    "#         websocket_port=None,\n",
    "#         websocket_port_default=7007,\n",
    "#         websocket_host='0.0.0.0',\n",
    "#         num_rays_per_chunk=32768,\n",
    "#         max_num_display_images=512,\n",
    "#         quit_on_train_completion=False,\n",
    "#         image_format='jpeg',\n",
    "#         jpeg_quality=75,\n",
    "#         make_share_url=False,\n",
    "#         camera_frustum_scale=0.1,\n",
    "#         default_composite_depth=True\n",
    "#     ),\n",
    "#     pipeline=VanillaPipelineConfig(\n",
    "#         _target=<class 'nerfstudio.pipelines.base_pipeline.VanillaPipeline'>,\n",
    "#         datamanager=ParallelDataManagerConfig(\n",
    "#             _target=<class 'nerfstudio.data.datamanagers.parallel_datamanager.ParallelDataManager'>,\n",
    "#             data=PosixPath('kiri_engine'),\n",
    "#             masks_on_gpu=False,\n",
    "#             images_on_gpu=False,\n",
    "#             dataparser=NerfstudioDataParserConfig(\n",
    "#                 _target=<class 'nerfstudio.data.dataparsers.nerfstudio_dataparser.Nerfstudio'>,\n",
    "#                 data=PosixPath('.'),\n",
    "#                 scale_factor=1.0,\n",
    "#                 downscale_factor=None,\n",
    "#                 scene_scale=1.0,\n",
    "#                 orientation_method='up',\n",
    "#                 center_method='poses',\n",
    "#                 auto_scale_poses=True,\n",
    "#                 eval_mode='fraction',\n",
    "#                 train_split_fraction=0.9,\n",
    "#                 eval_interval=8,\n",
    "#                 depth_unit_scale_factor=0.001,\n",
    "#                 mask_color=None,\n",
    "#                 load_3D_points=False\n",
    "#             ),\n",
    "#             train_num_rays_per_batch=4096,\n",
    "#             train_num_images_to_sample_from=-1,\n",
    "#             train_num_times_to_repeat_images=-1,\n",
    "#             eval_num_rays_per_batch=4096,\n",
    "#             eval_num_images_to_sample_from=-1,\n",
    "#             eval_num_times_to_repeat_images=-1,\n",
    "#             eval_image_indices=(0,),\n",
    "#             collate_fn=<function nerfstudio_collate at 0x7f3c753b5ab0>,\n",
    "#             camera_res_scale_factor=1.0,\n",
    "#             patch_size=1,\n",
    "#             camera_optimizer=None,\n",
    "#             pixel_sampler=PixelSamplerConfig(\n",
    "#                 _target=<class 'nerfstudio.data.pixel_samplers.PixelSampler'>,\n",
    "#                 num_rays_per_batch=4096,\n",
    "#                 keep_full_image=False,\n",
    "#                 is_equirectangular=False,\n",
    "#                 ignore_mask=False,\n",
    "#                 fisheye_crop_radius=None,\n",
    "#                 rejection_sample_mask=True,\n",
    "#                 max_num_iterations=100\n",
    "#             ),\n",
    "#             num_processes=1,\n",
    "#             queue_size=2,\n",
    "#             max_thread_workers=None\n",
    "#         ),\n",
    "#         model=NerfactoModelConfig(\n",
    "#             _target=<class 'nerfstudio.models.nerfacto.NerfactoModel'>,\n",
    "#             enable_collider=True,\n",
    "#             collider_params={'near_plane': 2.0, 'far_plane': 6.0},\n",
    "#             loss_coefficients={'rgb_loss_coarse': 1.0, 'rgb_loss_fine': 1.0},\n",
    "#             eval_num_rays_per_chunk=32768,\n",
    "#             prompt=None,\n",
    "#             near_plane=0.05,\n",
    "#             far_plane=1000.0,\n",
    "#             background_color='last_sample',\n",
    "#             hidden_dim=64,\n",
    "#             hidden_dim_color=64,\n",
    "#             hidden_dim_transient=64,\n",
    "#             num_levels=16,\n",
    "#             base_res=16,\n",
    "#             max_res=2048,\n",
    "#             log2_hashmap_size=19,\n",
    "#             features_per_level=2,\n",
    "#             num_proposal_samples_per_ray=(256, 96),\n",
    "#             num_nerf_samples_per_ray=48,\n",
    "#             proposal_update_every=5,\n",
    "#             proposal_warmup=5000,\n",
    "#             num_proposal_iterations=2,\n",
    "#             use_same_proposal_network=False,\n",
    "#             proposal_net_args_list=[\n",
    "#                 {'hidden_dim': 16, 'log2_hashmap_size': 17, 'num_levels': 5, 'max_res': 128, 'use_linear': False},\n",
    "#                 {'hidden_dim': 16, 'log2_hashmap_size': 17, 'num_levels': 5, 'max_res': 256, 'use_linear': False}\n",
    "#             ],\n",
    "#             proposal_initial_sampler='piecewise',\n",
    "#             interlevel_loss_mult=1.0,\n",
    "#             distortion_loss_mult=0.002,\n",
    "#             orientation_loss_mult=0.0001,\n",
    "#             pred_normal_loss_mult=0.001,\n",
    "#             use_proposal_weight_anneal=True,\n",
    "#             use_appearance_embedding=True,\n",
    "#             use_average_appearance_embedding=True,\n",
    "#             proposal_weights_anneal_slope=10.0,\n",
    "#             proposal_weights_anneal_max_num_iters=1000,\n",
    "#             use_single_jitter=True,\n",
    "#             predict_normals=False,\n",
    "#             disable_scene_contraction=False,\n",
    "#             use_gradient_scaling=False,\n",
    "#             implementation='tcnn',\n",
    "#             appearance_embed_dim=32,\n",
    "#             average_init_density=0.01,\n",
    "#             camera_optimizer=CameraOptimizerConfig(\n",
    "#                 _target=<class 'nerfstudio.cameras.camera_optimizers.CameraOptimizer'>,\n",
    "#                 mode='SO3xR3',\n",
    "#                 trans_l2_penalty=0.01,\n",
    "#                 rot_l2_penalty=0.001,\n",
    "#                 optimizer=None,\n",
    "#                 scheduler=None\n",
    "#             )\n",
    "#         )\n",
    "#     ),\n",
    "#     optimizers={\n",
    "#         'proposal_networks': {\n",
    "#             'optimizer': AdamOptimizerConfig(\n",
    "#                 _target=<class 'torch.optim.adam.Adam'>,\n",
    "#                 lr=0.01,\n",
    "#                 eps=1e-15,\n",
    "#                 max_norm=None,\n",
    "#                 weight_decay=0\n",
    "#             ),\n",
    "#             'scheduler': ExponentialDecaySchedulerConfig(\n",
    "#                 _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,\n",
    "#                 lr_pre_warmup=1e-08,\n",
    "#                 lr_final=0.0001,\n",
    "#                 warmup_steps=0,\n",
    "#                 max_steps=200000,\n",
    "#                 ramp='cosine'\n",
    "#             )\n",
    "#         },\n",
    "#         'fields': {\n",
    "#             'optimizer': AdamOptimizerConfig(\n",
    "#                 _target=<class 'torch.optim.adam.Adam'>,\n",
    "#                 lr=0.01,\n",
    "#                 eps=1e-15,\n",
    "#                 max_norm=None,\n",
    "#                 weight_decay=0\n",
    "#             ),\n",
    "#             'scheduler': ExponentialDecaySchedulerConfig(\n",
    "#                 _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,\n",
    "#                 lr_pre_warmup=1e-08,\n",
    "#                 lr_final=0.0001,\n",
    "#                 warmup_steps=0,\n",
    "#                 max_steps=200000,\n",
    "#                 ramp='cosine'\n",
    "#             )\n",
    "#         },\n",
    "#         'camera_opt': {\n",
    "#             'optimizer': AdamOptimizerConfig(\n",
    "#                 _target=<class 'torch.optim.adam.Adam'>,\n",
    "#                 lr=0.001,\n",
    "#                 eps=1e-15,\n",
    "#                 max_norm=None,\n",
    "#                 weight_decay=0\n",
    "#             ),\n",
    "#             'scheduler': ExponentialDecaySchedulerConfig(\n",
    "#                 _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,\n",
    "#                 lr_pre_warmup=1e-08,\n",
    "#                 lr_final=0.0001,\n",
    "#                 warmup_steps=0,\n",
    "#                 max_steps=5000,\n",
    "#                 ramp='cosine'\n",
    "#             )\n",
    "#         }\n",
    "#     },\n",
    "#     vis='viewer',\n",
    "#     data=PosixPath('kiri_engine'),\n",
    "#     prompt=None,\n",
    "#     relative_model_dir=PosixPath('nerfstudio_models'),\n",
    "#     load_scheduler=True,\n",
    "#     steps_per_save=2000,\n",
    "#     steps_per_eval_batch=500,\n",
    "#     steps_per_eval_image=500,\n",
    "#     steps_per_eval_all_images=25000,\n",
    "#     max_num_iterations=30000,\n",
    "#     mixed_precision=True,\n",
    "#     use_grad_scaler=False,\n",
    "#     save_only_latest_checkpoint=True,\n",
    "#     load_dir=None,\n",
    "#     load_step=None,\n",
    "#     load_config=None,\n",
    "#     load_checkpoint=None,\n",
    "#     log_gradients=False,\n",
    "#     gradient_accumulation_steps={}\n",
    "# )\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#            Saving config to: outputs/kiri_engine/nerfacto/2024-07-09_121238/config.yml          \u001b]8;id=182774;file:///home/user/nerfstudio/nerfstudio/configs/experiment_config.py\u001b\\experiment_config.py\u001b]8;;\u001b\\:\u001b]8;id=780818;file:///home/user/nerfstudio/nerfstudio/configs/experiment_config.py#136\u001b\\136\u001b]8;;\u001b\\\n",
    "#            Saving checkpoints to: outputs/kiri_engine/nerfacto/2024-07-09_121238/nerfstudio_models        \u001b]8;id=234053;file:///home/user/nerfstudio/nerfstudio/engine/trainer.py\u001b\\trainer.py\u001b]8;;\u001b\\:\u001b]8;id=146316;file:///home/user/nerfstudio/nerfstudio/engine/trainer.py#137\u001b\\137\u001b]8;;\u001b\\\n",
    "#            Auto image downscale factor of 2                                                 \u001b]8;id=91161;file:///home/user/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\nerfstudio_dataparser.py\u001b]8;;\u001b\\:\u001b]8;id=619176;file:///home/user/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#484\u001b\\484\u001b]8;;\u001b\\\n",
    "# Started threads\n",
    "# Setting up evaluation dataset...\n",
    "# Caching all 28 images.\n",
    "# Loading data batch â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:00m 0:00:01\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ viser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "# â”‚             â•·                       â”‚\n",
    "# â”‚   HTTP      â”‚ http://0.0.0.0:7007   â”‚\n",
    "# â”‚   Websocket â”‚ ws://0.0.0.0:7007     â”‚\n",
    "# â”‚             â•µ                       â”‚\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "# [NOTE] Not running eval iterations since only viewer is enabled.\n",
    "# Use --vis {wandb, tensorboard, viewer+wandb, viewer+tensorboard} to run with eval.\n",
    "# No Nerfstudio checkpoint to load, so training from scratch.\n",
    "# Disabled comet/tensorboard/wandb event writers\n",
    "# [12:12:45] disabled local writer                                                                           \u001b]8;id=45561;file:///home/user/nerfstudio/nerfstudio/utils/writer.py\u001b\\writer.py\u001b]8;;\u001b\\:\u001b]8;id=765179;file:///home/user/nerfstudio/nerfstudio/utils/writer.py#185\u001b\\185\u001b]8;;\u001b\\\n",
    "# (viser) Connection opened (0, 1 total), 1365 persistent messages\n",
    "# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ‰ Training Finished ğŸ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "# â”‚                        â•·                                                                    â”‚\n",
    "# â”‚   Config File          â”‚ outputs/kiri_engine/nerfacto/2024-07-09_121238/config.yml          â”‚\n",
    "# â”‚   Checkpoint Directory â”‚ outputs/kiri_engine/nerfacto/2024-07-09_121238/nerfstudio_models   â”‚\n",
    "# â”‚                        â•µ                                                                    â”‚\n",
    "# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "#                                                    Use ctrl+c to quit                                       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
