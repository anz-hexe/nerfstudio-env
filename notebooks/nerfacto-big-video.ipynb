{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*defacto* method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ns-process-data video --data videoo/video_2024-07-02_18-43-16.mp4 --output-dir processed_video_1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` log\n",
    "Number of frames in video: 2157\n",
    "Number of frames to extract: 309\n",
    "[21:55:00] ğŸ‰ Done converting video to images.                                                 \u001b]8;id=646594;file:///home/user/nerfstudio/nerfstudio/process_data/process_data_utils.py\u001b\\process_data_utils.py\u001b]8;;\u001b\\:\u001b]8;id=576143;file:///home/user/nerfstudio/nerfstudio/process_data/process_data_utils.py#219\u001b\\219\u001b]8;;\u001b\\\n",
    "(    â— ) Converting video to images...\n",
    "ğŸŒ—  Running COLMAP feature extractor...tor...\n",
    "[21:55:04] ğŸ‰ Done extracting COLMAP features.                                                       \u001b]8;id=264983;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py\u001b\\colmap_utils.py\u001b]8;;\u001b\\:\u001b]8;id=831919;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py#137\u001b\\137\u001b]8;;\u001b\\\n",
    "ğŸš¶  Running COLMAP feature matcher...0m\n",
    "[21:55:17] ğŸ‰ Done matching COLMAP features.                                                         \u001b]8;id=106956;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py\u001b\\colmap_utils.py\u001b]8;;\u001b\\:\u001b]8;id=289375;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py#151\u001b\\151\u001b]8;;\u001b\\\n",
    "âŠ™ Running COLMAP bundle adjustment... (This may take a while)0m\n",
    "[21:55:59] ğŸ‰ Done COLMAP bundle adjustment.                                                         \u001b]8;id=898019;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py\u001b\\colmap_utils.py\u001b]8;;\u001b\\:\u001b]8;id=148746;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py#173\u001b\\173\u001b]8;;\u001b\\\n",
    "b Refine intrinsics...0m\n",
    "[21:56:02] ğŸ‰ Done refining intrinsics.                                                              \u001b]8;id=629284;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py\u001b\\colmap_utils.py\u001b]8;;\u001b\\:\u001b]8;id=732496;file:///home/user/nerfstudio/nerfstudio/process_data/colmap_utils.py#184\u001b\\184\u001b]8;;\u001b\\\n",
    ". Saving results to transforms.json0m\n",
    "[21:56:03] ğŸ‰ ğŸ‰ ğŸ‰ All DONE ğŸ‰ ğŸ‰ ğŸ‰                                                 \u001b]8;id=344626;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py\u001b\\video_to_nerfstudio_dataset.py\u001b]8;;\u001b\\:\u001b]8;id=162172;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py#142\u001b\\142\u001b]8;;\u001b\\\n",
    "           Starting with 2157 video frames                                            \u001b]8;id=941317;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py\u001b\\video_to_nerfstudio_dataset.py\u001b]8;;\u001b\\:\u001b]8;id=644603;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py#145\u001b\\145\u001b]8;;\u001b\\\n",
    "           We extracted 309 images with prefix 'frame_'                               \u001b]8;id=869437;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py\u001b\\video_to_nerfstudio_dataset.py\u001b]8;;\u001b\\:\u001b]8;id=930408;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py#145\u001b\\145\u001b]8;;\u001b\\\n",
    "           Colmap matched 308 images                                                  \u001b]8;id=757911;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py\u001b\\video_to_nerfstudio_dataset.py\u001b]8;;\u001b\\:\u001b]8;id=893839;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py#145\u001b\\145\u001b]8;;\u001b\\\n",
    "           COLMAP found poses for 99.68% of the images.                               \u001b]8;id=3769;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py\u001b\\video_to_nerfstudio_dataset.py\u001b]8;;\u001b\\:\u001b]8;id=533736;file:///home/user/nerfstudio/nerfstudio/process_data/video_to_nerfstudio_dataset.py#145\u001b\\145\u001b]8;;\u001b\\\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ns-train nerfacto-big --logging.local-writer.enable=False --data processed_video_1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` log \n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TrainerConfig(\n",
    "    _target=<class 'nerfstudio.engine.trainer.Trainer'>,\n",
    "    output_dir=PosixPath('outputs'),\n",
    "    method_name='nerfacto',\n",
    "    experiment_name=None,\n",
    "    project_name='nerfstudio-project',\n",
    "    timestamp='2024-07-02_200125',\n",
    "    machine=MachineConfig(seed=42, num_devices=1, num_machines=1, machine_rank=0, dist_url='auto', device_type='cuda'),\n",
    "    logging=LoggingConfig(\n",
    "        relative_log_dir=PosixPath('.'),\n",
    "        steps_per_log=10,\n",
    "        max_buffer_size=20,\n",
    "        local_writer=LocalWriterConfig(\n",
    "            _target=<class 'nerfstudio.utils.writer.LocalWriter'>,\n",
    "            enable=False,\n",
    "            stats_to_track=(\n",
    "                <EventName.ITER_TRAIN_TIME: 'Train Iter (time)'>,\n",
    "                <EventName.TRAIN_RAYS_PER_SEC: 'Train Rays / Sec'>,\n",
    "                <EventName.CURR_TEST_PSNR: 'Test PSNR'>,\n",
    "                <EventName.VIS_RAYS_PER_SEC: 'Vis Rays / Sec'>,\n",
    "                <EventName.TEST_RAYS_PER_SEC: 'Test Rays / Sec'>,\n",
    "                <EventName.ETA: 'ETA (time)'>\n",
    "            ),\n",
    "            max_log_size=10\n",
    "        ),\n",
    "        profiler='basic'\n",
    "    ),\n",
    "    viewer=ViewerConfig(\n",
    "        relative_log_filename='viewer_log_filename.txt',\n",
    "        websocket_port=None,\n",
    "        websocket_port_default=7007,\n",
    "        websocket_host='0.0.0.0',\n",
    "        num_rays_per_chunk=32768,\n",
    "        max_num_display_images=512,\n",
    "        quit_on_train_completion=False,\n",
    "        image_format='jpeg',\n",
    "        jpeg_quality=75,\n",
    "        make_share_url=False,\n",
    "        camera_frustum_scale=0.1,\n",
    "        default_composite_depth=True\n",
    "    ),\n",
    "    pipeline=VanillaPipelineConfig(\n",
    "        _target=<class 'nerfstudio.pipelines.base_pipeline.VanillaPipeline'>,\n",
    "        datamanager=ParallelDataManagerConfig(\n",
    "            _target=<class 'nerfstudio.data.datamanagers.parallel_datamanager.ParallelDataManager'>,\n",
    "            data=PosixPath('processed_video_1'),\n",
    "            masks_on_gpu=False,\n",
    "            images_on_gpu=False,\n",
    "            dataparser=NerfstudioDataParserConfig(\n",
    "                _target=<class 'nerfstudio.data.dataparsers.nerfstudio_dataparser.Nerfstudio'>,\n",
    "                data=PosixPath('.'),\n",
    "                scale_factor=1.0,\n",
    "                downscale_factor=None,\n",
    "                scene_scale=1.0,\n",
    "                orientation_method='up',\n",
    "                center_method='poses',\n",
    "                auto_scale_poses=True,\n",
    "                eval_mode='fraction',\n",
    "                train_split_fraction=0.9,\n",
    "                eval_interval=8,\n",
    "                depth_unit_scale_factor=0.001,\n",
    "                mask_color=None,\n",
    "                load_3D_points=False\n",
    "            ),\n",
    "            train_num_rays_per_batch=8192,\n",
    "            train_num_images_to_sample_from=-1,\n",
    "            train_num_times_to_repeat_images=-1,\n",
    "            eval_num_rays_per_batch=4096,\n",
    "            eval_num_images_to_sample_from=-1,\n",
    "            eval_num_times_to_repeat_images=-1,\n",
    "            eval_image_indices=(0,),\n",
    "            collate_fn=<function nerfstudio_collate at 0x7f4ab33b9ab0>,\n",
    "            camera_res_scale_factor=1.0,\n",
    "            patch_size=1,\n",
    "            camera_optimizer=None,\n",
    "            pixel_sampler=PixelSamplerConfig(\n",
    "                _target=<class 'nerfstudio.data.pixel_samplers.PixelSampler'>,\n",
    "                num_rays_per_batch=4096,\n",
    "                keep_full_image=False,\n",
    "                is_equirectangular=False,\n",
    "                ignore_mask=False,\n",
    "                fisheye_crop_radius=None,\n",
    "                rejection_sample_mask=True,\n",
    "                max_num_iterations=100\n",
    "            ),\n",
    "            num_processes=1,\n",
    "            queue_size=2,\n",
    "            max_thread_workers=None\n",
    "        ),\n",
    "        model=NerfactoModelConfig(\n",
    "            _target=<class 'nerfstudio.models.nerfacto.NerfactoModel'>,\n",
    "            enable_collider=True,\n",
    "            collider_params={'near_plane': 2.0, 'far_plane': 6.0},\n",
    "            loss_coefficients={'rgb_loss_coarse': 1.0, 'rgb_loss_fine': 1.0},\n",
    "            eval_num_rays_per_chunk=32768,\n",
    "            prompt=None,\n",
    "            near_plane=0.05,\n",
    "            far_plane=1000.0,\n",
    "            background_color='last_sample',\n",
    "            hidden_dim=128,\n",
    "            hidden_dim_color=128,\n",
    "            hidden_dim_transient=64,\n",
    "            num_levels=16,\n",
    "            base_res=16,\n",
    "            max_res=4096,\n",
    "            log2_hashmap_size=21,\n",
    "            features_per_level=2,\n",
    "            num_proposal_samples_per_ray=(512, 256),\n",
    "            num_nerf_samples_per_ray=128,\n",
    "            proposal_update_every=5,\n",
    "            proposal_warmup=5000,\n",
    "            num_proposal_iterations=2,\n",
    "            use_same_proposal_network=False,\n",
    "            proposal_net_args_list=[\n",
    "                {'hidden_dim': 16, 'log2_hashmap_size': 17, 'num_levels': 5, 'max_res': 128, 'use_linear': False},\n",
    "                {'hidden_dim': 16, 'log2_hashmap_size': 17, 'num_levels': 5, 'max_res': 256, 'use_linear': False}\n",
    "            ],\n",
    "            proposal_initial_sampler='piecewise',\n",
    "            interlevel_loss_mult=1.0,\n",
    "            distortion_loss_mult=0.002,\n",
    "            orientation_loss_mult=0.0001,\n",
    "            pred_normal_loss_mult=0.001,\n",
    "            use_proposal_weight_anneal=True,\n",
    "            use_appearance_embedding=True,\n",
    "            use_average_appearance_embedding=True,\n",
    "            proposal_weights_anneal_slope=10.0,\n",
    "            proposal_weights_anneal_max_num_iters=5000,\n",
    "            use_single_jitter=True,\n",
    "            predict_normals=False,\n",
    "            disable_scene_contraction=False,\n",
    "            use_gradient_scaling=False,\n",
    "            implementation='tcnn',\n",
    "            appearance_embed_dim=128,\n",
    "            average_init_density=0.01,\n",
    "            camera_optimizer=CameraOptimizerConfig(\n",
    "                _target=<class 'nerfstudio.cameras.camera_optimizers.CameraOptimizer'>,\n",
    "                mode='SO3xR3',\n",
    "                trans_l2_penalty=0.01,\n",
    "                rot_l2_penalty=0.001,\n",
    "                optimizer=None,\n",
    "                scheduler=None\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    optimizers={\n",
    "        'proposal_networks': {\n",
    "            'optimizer': RAdamOptimizerConfig(\n",
    "                _target=<class 'torch.optim.radam.RAdam'>,\n",
    "                lr=0.01,\n",
    "                eps=1e-15,\n",
    "                max_norm=None,\n",
    "                weight_decay=0\n",
    "            ),\n",
    "            'scheduler': None\n",
    "        },\n",
    "        'fields': {\n",
    "            'optimizer': RAdamOptimizerConfig(\n",
    "                _target=<class 'torch.optim.radam.RAdam'>,\n",
    "                lr=0.01,\n",
    "                eps=1e-15,\n",
    "                max_norm=None,\n",
    "                weight_decay=0\n",
    "            ),\n",
    "            'scheduler': ExponentialDecaySchedulerConfig(\n",
    "                _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,\n",
    "                lr_pre_warmup=1e-08,\n",
    "                lr_final=0.0001,\n",
    "                warmup_steps=0,\n",
    "                max_steps=50000,\n",
    "                ramp='cosine'\n",
    "            )\n",
    "        },\n",
    "        'camera_opt': {\n",
    "            'optimizer': AdamOptimizerConfig(\n",
    "                _target=<class 'torch.optim.adam.Adam'>,\n",
    "                lr=0.001,\n",
    "                eps=1e-15,\n",
    "                max_norm=None,\n",
    "                weight_decay=0\n",
    "            ),\n",
    "            'scheduler': ExponentialDecaySchedulerConfig(\n",
    "                _target=<class 'nerfstudio.engine.schedulers.ExponentialDecayScheduler'>,\n",
    "                lr_pre_warmup=1e-08,\n",
    "                lr_final=0.0001,\n",
    "                warmup_steps=0,\n",
    "                max_steps=5000,\n",
    "                ramp='cosine'\n",
    "            )\n",
    "        }\n",
    "    },\n",
    "    vis='viewer',\n",
    "    data=PosixPath('processed_video_1'),\n",
    "    prompt=None,\n",
    "    relative_model_dir=PosixPath('nerfstudio_models'),\n",
    "    load_scheduler=True,\n",
    "    steps_per_save=2000,\n",
    "    steps_per_eval_batch=500,\n",
    "    steps_per_eval_image=500,\n",
    "    steps_per_eval_all_images=25000,\n",
    "    max_num_iterations=100000,\n",
    "    mixed_precision=True,\n",
    "    use_grad_scaler=False,\n",
    "    save_only_latest_checkpoint=True,\n",
    "    load_dir=None,\n",
    "    load_step=None,\n",
    "    load_config=None,\n",
    "    load_checkpoint=None,\n",
    "    log_gradients=False,\n",
    "    gradient_accumulation_steps={}\n",
    ")\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "           Saving config to: outputs/processed_video_1/nerfacto/2024-07-02_200125/config.yml    \u001b]8;id=484655;file:///home/user/nerfstudio/nerfstudio/configs/experiment_config.py\u001b\\experiment_config.py\u001b]8;;\u001b\\:\u001b]8;id=152522;file:///home/user/nerfstudio/nerfstudio/configs/experiment_config.py#136\u001b\\136\u001b]8;;\u001b\\\n",
    "           Saving checkpoints to: outputs/processed_video_1/nerfacto/2024-07-02_200125/nerfstudio_models  \u001b]8;id=234053;file:///home/user/nerfstudio/nerfstudio/engine/trainer.py\u001b\\trainer.py\u001b]8;;\u001b\\:\u001b]8;id=146316;file:///home/user/nerfstudio/nerfstudio/engine/trainer.py#137\u001b\\137\u001b]8;;\u001b\\\n",
    "           Auto image downscale factor of 1                                                 \u001b]8;id=91161;file:///home/user/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\nerfstudio_dataparser.py\u001b]8;;\u001b\\:\u001b]8;id=619176;file:///home/user/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#484\u001b\\484\u001b]8;;\u001b\\\n",
    "Started threads\n",
    "Setting up evaluation dataset...\n",
    "Caching all 30 images.\n",
    "Loading data batch â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  44% 0:00:01â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ viser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "â”‚             â•·                       â”‚\n",
    "â”‚   HTTP      â”‚ http://0.0.0.0:7007   â”‚\n",
    "â”‚   Websocket â”‚ ws://0.0.0.0:7007     â”‚\n",
    "â”‚             â•µ                       â”‚\n",
    "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "Loading data batch â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:00m 0:00:01\n",
    "[NOTE] Not running eval iterations since only viewer is enabled.\n",
    "Use --vis {wandb, tensorboard, viewer+wandb, viewer+tensorboard} to run with eval.\n",
    "No Nerfstudio checkpoint to load, so training from scratch.\n",
    "Disabled comet/tensorboard/wandb event writers\n",
    "[20:01:32] disabled local writer                                                                           \u001b]8;id=45561;file:///home/user/nerfstudio/nerfstudio/utils/writer.py\u001b\\writer.py\u001b]8;;\u001b\\:\u001b]8;id=765179;file:///home/user/nerfstudio/nerfstudio/utils/writer.py#185\u001b\\185\u001b]8;;\u001b\\\n",
    "(viser) Connection opened (0, 1 total), 1485 persistent messages\n",
    "â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ‰ Training Finished ğŸ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "â”‚                        â•·                                                                          â”‚\n",
    "â”‚   Config File          â”‚ outputs/processed_video_1/nerfacto/2024-07-02_200125/config.yml          â”‚\n",
    "â”‚   Checkpoint Directory â”‚ outputs/processed_video_1/nerfacto/2024-07-02_200125/nerfstudio_models   â”‚\n",
    "â”‚                        â•µ                                                                          â”‚\n",
    "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "                                                   Use ctrl+c to quit                                                   \n",
    "(viser) Connection closed (0, 0 total)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ns-viewer --load-config outputs/processed_video_1/nerfacto/2024-07-02_200125/config.yml --viewer.websocket-port 7002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` log\n",
    "[18:08:29] Auto image downscale factor of 1                                                 \u001b]8;id=134068;file:///home/user/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\nerfstudio_dataparser.py\u001b]8;;\u001b\\:\u001b]8;id=307965;file:///home/user/nerfstudio/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#484\u001b\\484\u001b]8;;\u001b\\\n",
    "Started threads\n",
    "Setting up evaluation dataset...\n",
    "Caching all 30 images.\n",
    "Loading data batch â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  44% 0:00:01Loading latest checkpoint from load_dir\n",
    "Loading data batch â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:00m 0:00:01\n",
    "âœ… Done loading checkpoint from \n",
    "outputs/processed_video_1/nerfacto/2024-07-02_200125/nerfstudio_models/step-000099999.ckpt\n",
    "â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ viser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n",
    "â”‚             â•·                       â”‚\n",
    "â”‚   HTTP      â”‚ http://0.0.0.0:7002   â”‚\n",
    "â”‚   Websocket â”‚ ws://0.0.0.0:7002     â”‚\n",
    "â”‚             â•µ                       â”‚\n",
    "â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n",
    "[18:08:37] disabled local writer                                                                           \u001b]8;id=789559;file:///home/user/nerfstudio/nerfstudio/utils/writer.py\u001b\\writer.py\u001b]8;;\u001b\\:\u001b]8;id=830447;file:///home/user/nerfstudio/nerfstudio/utils/writer.py#185\u001b\\185\u001b]8;;\u001b\\\n",
    "(viser) Connection opened (0, 1 total), 1485 persistent messages\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
